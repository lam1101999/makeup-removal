{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Any\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup device and tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24aefb6e2b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, list_root_dir: list, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.list_root_dir = list_root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        for root_dir in list_root_dir:\n",
    "            self.image_paths.extend(\n",
    "                glob.glob(os.path.join(root_dir, \"with\", \"*.jpg\")))\n",
    "            self.image_paths.extend(\n",
    "                glob.glob(os.path.join(root_dir, \"without\", \"*.jpg\")))\n",
    "        random.shuffle(self.image_paths)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        image_path = self.image_paths[index]\n",
    "\n",
    "        label = 1 if image_path.split(os.sep)[-2] == \"with\" else 0\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_function, optimizer, train_loader, writer, epoch=1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Clear gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate logits\n",
    "        outputs = model(images)\n",
    "        # Calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # Calculate gradient from loss\n",
    "        loss.backward()\n",
    "        # Update weight\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate loss\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # Calculate total sample in data_loader\n",
    "        total_samples += images.size(0)\n",
    "        # Calculte y_predict for evaluation\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.detach().cpu().numpy())\n",
    "    loss = running_loss/total_samples\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    writer.add_scalar(\"train/loss\", loss, epoch)\n",
    "    writer.add_scalar(\"train/accuracy\", accuracy, epoch)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loss_function, test_dataloader, writer, epoch):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Calculate logits\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate loss of outputs and y_true\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            # Calculate total sample\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "            # Calculte y_predict for evaluation\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.detach().cpu().numpy())\n",
    "    loss = total_loss/total_samples\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    writer.add_scalar(\"test/loss\", loss, epoch)\n",
    "    writer.add_scalar(\"test/accuracy\", accuracy, epoch)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet34(num_classes=2)\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss 0.6923, train_acc 0.5311, test_loss 0.6929330935861773, test_acc 0.5814\n",
      "epoch 1: train_loss 0.6924, train_acc 0.53, test_loss 0.6928534517558445, test_acc 0.5814\n",
      "epoch 2: train_loss 0.6923, train_acc 0.5308, test_loss 0.6928335264788249, test_acc 0.5814\n",
      "epoch 3: train_loss 0.6923, train_acc 0.5252, test_loss 0.6929117808394284, test_acc 0.5804\n",
      "epoch 4: train_loss 0.6922, train_acc 0.5396, test_loss 0.6928274711045748, test_acc 0.5137\n",
      "epoch 5: train_loss 0.6922, train_acc 0.5326, test_loss 0.6907804782691341, test_acc 0.5192\n",
      "epoch 6: train_loss 0.6922, train_acc 0.5259, test_loss 0.6907749721947274, test_acc 0.5338\n",
      "epoch 7: train_loss 0.6923, train_acc 0.5289, test_loss 0.6901662920685093, test_acc 0.5356\n",
      "epoch 8: train_loss 0.6922, train_acc 0.5294, test_loss 0.6903439388632556, test_acc 0.543\n",
      "epoch 9: train_loss 0.6923, train_acc 0.5218, test_loss 0.6903235368580444, test_acc 0.5448\n",
      "epoch 10: train_loss 0.6923, train_acc 0.5299, test_loss 0.6901334370511977, test_acc 0.5466\n",
      "epoch 11: train_loss 0.6925, train_acc 0.5259, test_loss 0.6901110643878497, test_acc 0.5411\n",
      "epoch 12: train_loss 0.6923, train_acc 0.524, test_loss 0.6905983813937883, test_acc 0.5484\n",
      "epoch 13: train_loss 0.6923, train_acc 0.5262, test_loss 0.6907507051497535, test_acc 0.5466\n",
      "epoch 14: train_loss 0.6924, train_acc 0.5287, test_loss 0.6902605022765165, test_acc 0.543\n",
      "epoch 15: train_loss 0.692, train_acc 0.535, test_loss 0.6903828928413949, test_acc 0.542\n",
      "epoch 16: train_loss 0.6921, train_acc 0.5339, test_loss 0.6906318154587824, test_acc 0.5448\n",
      "epoch 17: train_loss 0.6925, train_acc 0.5253, test_loss 0.690573364223815, test_acc 0.5475\n",
      "epoch 18: train_loss 0.6922, train_acc 0.5307, test_loss 0.6900820948959923, test_acc 0.5457\n",
      "epoch 19: train_loss 0.6923, train_acc 0.5324, test_loss 0.6900456168533897, test_acc 0.5448\n",
      "epoch 20: train_loss 0.6923, train_acc 0.5249, test_loss 0.6904636622564884, test_acc 0.5402\n",
      "epoch 21: train_loss 0.6922, train_acc 0.532, test_loss 0.6908522760410414, test_acc 0.5402\n",
      "epoch 22: train_loss 0.6923, train_acc 0.533, test_loss 0.6897425417272439, test_acc 0.5466\n",
      "epoch 23: train_loss 0.6922, train_acc 0.5297, test_loss 0.6901326519479699, test_acc 0.5466\n",
      "epoch 24: train_loss 0.6923, train_acc 0.5329, test_loss 0.6898953957139247, test_acc 0.5466\n",
      "epoch 25: train_loss 0.6923, train_acc 0.5313, test_loss 0.6906998319861222, test_acc 0.5393\n",
      "epoch 26: train_loss 0.6922, train_acc 0.5246, test_loss 0.6901988272693083, test_acc 0.5411\n",
      "epoch 27: train_loss 0.6922, train_acc 0.5236, test_loss 0.6899112762655157, test_acc 0.5457\n",
      "epoch 28: train_loss 0.6922, train_acc 0.5297, test_loss 0.6895414736850606, test_acc 0.5411\n",
      "epoch 29: train_loss 0.6923, train_acc 0.5252, test_loss 0.6902375804222916, test_acc 0.5494\n",
      "epoch 30: train_loss 0.6922, train_acc 0.5336, test_loss 0.6905894143271926, test_acc 0.543\n",
      "epoch 31: train_loss 0.6921, train_acc 0.5368, test_loss 0.6904043127021581, test_acc 0.5411\n",
      "epoch 32: train_loss 0.6921, train_acc 0.537, test_loss 0.6901647302524699, test_acc 0.5439\n",
      "epoch 33: train_loss 0.6923, train_acc 0.5321, test_loss 0.6906392012043453, test_acc 0.542\n",
      "epoch 34: train_loss 0.6921, train_acc 0.5341, test_loss 0.6903203587427436, test_acc 0.5448\n",
      "epoch 35: train_loss 0.6923, train_acc 0.5309, test_loss 0.6902618599984066, test_acc 0.5411\n",
      "epoch 36: train_loss 0.6924, train_acc 0.526, test_loss 0.6899306422177791, test_acc 0.5475\n",
      "epoch 37: train_loss 0.6923, train_acc 0.5335, test_loss 0.6903511206236357, test_acc 0.5411\n",
      "epoch 38: train_loss 0.6921, train_acc 0.5332, test_loss 0.6904250992499497, test_acc 0.5439\n",
      "epoch 39: train_loss 0.6923, train_acc 0.5386, test_loss 0.690405266267508, test_acc 0.543\n",
      "epoch 40: train_loss 0.6923, train_acc 0.5305, test_loss 0.6901259935534196, test_acc 0.5457\n",
      "epoch 41: train_loss 0.6923, train_acc 0.5273, test_loss 0.690834536630885, test_acc 0.5402\n",
      "epoch 42: train_loss 0.6923, train_acc 0.5252, test_loss 0.6902549110993171, test_acc 0.543\n",
      "epoch 43: train_loss 0.6923, train_acc 0.5256, test_loss 0.6901805279895636, test_acc 0.5411\n",
      "epoch 44: train_loss 0.6923, train_acc 0.5358, test_loss 0.6901945935960662, test_acc 0.5457\n",
      "epoch 45: train_loss 0.6925, train_acc 0.5215, test_loss 0.6906751748412793, test_acc 0.5448\n",
      "epoch 46: train_loss 0.6921, train_acc 0.533, test_loss 0.6902598053271417, test_acc 0.5448\n",
      "epoch 47: train_loss 0.6922, train_acc 0.5352, test_loss 0.6897978487354746, test_acc 0.5439\n",
      "epoch 48: train_loss 0.6922, train_acc 0.5288, test_loss 0.6904622966890144, test_acc 0.5503\n",
      "epoch 49: train_loss 0.6924, train_acc 0.5293, test_loss 0.6897250064112369, test_acc 0.5512\n",
      "epoch 50: train_loss 0.6922, train_acc 0.5374, test_loss 0.6901824222622231, test_acc 0.5494\n",
      "epoch 51: train_loss 0.6923, train_acc 0.5267, test_loss 0.690117704367071, test_acc 0.5448\n",
      "epoch 52: train_loss 0.6923, train_acc 0.5312, test_loss 0.6899493381353793, test_acc 0.542\n",
      "epoch 53: train_loss 0.6924, train_acc 0.5287, test_loss 0.6905369524328103, test_acc 0.5475\n",
      "epoch 54: train_loss 0.6924, train_acc 0.5363, test_loss 0.6907425632860369, test_acc 0.5475\n",
      "epoch 55: train_loss 0.6921, train_acc 0.5237, test_loss 0.6906603257660456, test_acc 0.5466\n",
      "epoch 56: train_loss 0.6923, train_acc 0.5282, test_loss 0.6901933478916803, test_acc 0.5457\n",
      "epoch 57: train_loss 0.6923, train_acc 0.5254, test_loss 0.6903543407999837, test_acc 0.5439\n",
      "epoch 58: train_loss 0.6924, train_acc 0.5284, test_loss 0.6904986293703808, test_acc 0.5338\n",
      "epoch 59: train_loss 0.6922, train_acc 0.5255, test_loss 0.690423661110824, test_acc 0.5466\n",
      "epoch 60: train_loss 0.6923, train_acc 0.5313, test_loss 0.6903214152813829, test_acc 0.5457\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v3_large(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"mobilenet_v3_large\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss 2.6591, train_acc 0.4917, test_loss 1.5725709575839626, test_acc 0.5311\n",
      "epoch 1: train_loss 2.6633, train_acc 0.4836, test_loss 2.7813341988070137, test_acc 0.5265\n",
      "epoch 2: train_loss 2.7235, train_acc 0.4821, test_loss 2.6274256297613627, test_acc 0.5393\n",
      "epoch 3: train_loss 2.6632, train_acc 0.4865, test_loss 3.1331885618309214, test_acc 0.5302\n",
      "epoch 4: train_loss 2.6484, train_acc 0.4814, test_loss 4.397794828118529, test_acc 0.5137\n",
      "epoch 5: train_loss 2.6105, train_acc 0.4858, test_loss 4.400562539288069, test_acc 0.5366\n",
      "epoch 6: train_loss 2.7231, train_acc 0.4862, test_loss 3.076007527014891, test_acc 0.5302\n",
      "epoch 7: train_loss 2.5961, train_acc 0.4939, test_loss 2.751560049257505, test_acc 0.5293\n",
      "epoch 8: train_loss 2.651, train_acc 0.4892, test_loss 4.243332407810135, test_acc 0.5384\n",
      "epoch 9: train_loss 2.6727, train_acc 0.4897, test_loss 4.146779999000716, test_acc 0.5247\n",
      "epoch 10: train_loss 2.6123, train_acc 0.4876, test_loss 4.379474850633681, test_acc 0.5174\n",
      "epoch 11: train_loss 2.7014, train_acc 0.4806, test_loss 3.9808503766382417, test_acc 0.5165\n",
      "epoch 12: train_loss 2.7366, train_acc 0.4841, test_loss 3.107831490323138, test_acc 0.5155\n",
      "epoch 13: train_loss 2.7223, train_acc 0.4824, test_loss 2.6825159127795066, test_acc 0.5293\n",
      "epoch 14: train_loss 2.6052, train_acc 0.49, test_loss 3.0584694419526093, test_acc 0.5219\n",
      "epoch 15: train_loss 2.5986, train_acc 0.4845, test_loss 3.022738637610371, test_acc 0.5256\n",
      "epoch 16: train_loss 2.6798, train_acc 0.4813, test_loss 3.511322278754149, test_acc 0.5119\n",
      "epoch 17: train_loss 2.6398, train_acc 0.4862, test_loss 2.972583748304866, test_acc 0.5137\n",
      "epoch 18: train_loss 2.6952, train_acc 0.4904, test_loss 2.900829964843485, test_acc 0.5265\n",
      "epoch 19: train_loss 2.7053, train_acc 0.4792, test_loss 3.556638168678423, test_acc 0.5384\n",
      "epoch 20: train_loss 2.6882, train_acc 0.48, test_loss 2.795218619611625, test_acc 0.5338\n",
      "epoch 21: train_loss 2.6007, train_acc 0.4883, test_loss 3.1873639303325954, test_acc 0.5338\n",
      "epoch 22: train_loss 2.6937, train_acc 0.4774, test_loss 2.228871656728183, test_acc 0.5238\n",
      "epoch 23: train_loss 2.6646, train_acc 0.4859, test_loss 3.226089383392055, test_acc 0.5274\n",
      "epoch 24: train_loss 2.6688, train_acc 0.4849, test_loss 2.9537502970730363, test_acc 0.5155\n",
      "epoch 25: train_loss 2.5987, train_acc 0.4846, test_loss 3.72697217165879, test_acc 0.5293\n",
      "epoch 26: train_loss 2.5857, train_acc 0.4896, test_loss 3.8468360395274606, test_acc 0.5265\n",
      "epoch 27: train_loss 2.7004, train_acc 0.4846, test_loss 3.417514232002621, test_acc 0.5283\n",
      "epoch 28: train_loss 2.6404, train_acc 0.4803, test_loss 2.864983815788351, test_acc 0.5347\n",
      "epoch 29: train_loss 2.5421, train_acc 0.4919, test_loss 3.794812891121538, test_acc 0.5155\n",
      "epoch 30: train_loss 2.7214, train_acc 0.4815, test_loss 3.2987821507497506, test_acc 0.5311\n",
      "epoch 31: train_loss 2.7114, train_acc 0.4842, test_loss 3.639810166367665, test_acc 0.5347\n",
      "epoch 32: train_loss 2.576, train_acc 0.4836, test_loss 3.3470368394032257, test_acc 0.5439\n",
      "epoch 33: train_loss 2.6127, train_acc 0.49, test_loss 3.0456186681168607, test_acc 0.5475\n",
      "epoch 34: train_loss 2.5988, train_acc 0.4883, test_loss 3.7349267980080416, test_acc 0.5238\n",
      "epoch 35: train_loss 2.6031, train_acc 0.4853, test_loss 2.472920310126798, test_acc 0.5347\n",
      "epoch 36: train_loss 2.6681, train_acc 0.4819, test_loss 3.421635877933537, test_acc 0.532\n",
      "epoch 37: train_loss 2.6843, train_acc 0.4924, test_loss 2.873432572679066, test_acc 0.5293\n",
      "epoch 38: train_loss 2.6417, train_acc 0.4876, test_loss 3.7271145259658423, test_acc 0.5375\n",
      "epoch 39: train_loss 2.6276, train_acc 0.4878, test_loss 2.2880245146411426, test_acc 0.5475\n",
      "epoch 40: train_loss 2.6859, train_acc 0.4811, test_loss 2.9984394093972018, test_acc 0.5238\n",
      "epoch 41: train_loss 2.6408, train_acc 0.4825, test_loss 3.728880378020965, test_acc 0.5393\n",
      "epoch 42: train_loss 2.6174, train_acc 0.4835, test_loss 2.2640532470926287, test_acc 0.5448\n",
      "epoch 43: train_loss 2.6429, train_acc 0.4882, test_loss 2.7816890144696838, test_acc 0.5329\n",
      "epoch 44: train_loss 2.6284, train_acc 0.4864, test_loss 2.6109307219820876, test_acc 0.5366\n",
      "epoch 45: train_loss 2.6424, train_acc 0.4857, test_loss 2.2837151988550777, test_acc 0.5338\n",
      "epoch 46: train_loss 2.7249, train_acc 0.4845, test_loss 3.201074126651562, test_acc 0.5366\n",
      "epoch 47: train_loss 2.6449, train_acc 0.488, test_loss 3.457007077973765, test_acc 0.5338\n",
      "epoch 48: train_loss 2.6767, train_acc 0.4859, test_loss 3.4025622426482833, test_acc 0.5484\n",
      "epoch 49: train_loss 2.6508, train_acc 0.4859, test_loss 2.927568513688919, test_acc 0.532\n",
      "epoch 50: train_loss 2.6509, train_acc 0.4886, test_loss 6.3427767714373156, test_acc 0.5119\n",
      "epoch 51: train_loss 2.6328, train_acc 0.4919, test_loss 2.7329667525491943, test_acc 0.5174\n",
      "epoch 52: train_loss 2.6004, train_acc 0.4892, test_loss 4.546596678998832, test_acc 0.5448\n",
      "epoch 53: train_loss 2.6157, train_acc 0.4936, test_loss 2.817401406969841, test_acc 0.532\n",
      "epoch 54: train_loss 2.6999, train_acc 0.4785, test_loss 2.830943523638863, test_acc 0.5256\n",
      "epoch 55: train_loss 2.661, train_acc 0.4812, test_loss 3.046635111899437, test_acc 0.5366\n",
      "epoch 56: train_loss 2.6672, train_acc 0.4863, test_loss 1.7394640331294462, test_acc 0.5439\n",
      "epoch 57: train_loss 2.6122, train_acc 0.4892, test_loss 2.4112245992942962, test_acc 0.532\n",
      "epoch 58: train_loss 2.7127, train_acc 0.4883, test_loss 3.3728947136040364, test_acc 0.5283\n",
      "epoch 59: train_loss 2.6442, train_acc 0.4905, test_loss 4.464886486748237, test_acc 0.5165\n",
      "epoch 60: train_loss 2.6802, train_acc 0.4792, test_loss 3.935264151427602, test_acc 0.532\n",
      "epoch 61: train_loss 2.573, train_acc 0.48, test_loss 2.975530794159368, test_acc 0.5274\n",
      "epoch 62: train_loss 2.6733, train_acc 0.478, test_loss 3.2278268621652173, test_acc 0.5293\n",
      "epoch 63: train_loss 2.662, train_acc 0.4863, test_loss 2.2196865698537183, test_acc 0.5475\n",
      "epoch 64: train_loss 2.7008, train_acc 0.4856, test_loss 3.1174139162522128, test_acc 0.5183\n",
      "epoch 65: train_loss 2.6738, train_acc 0.489, test_loss 3.506556270545318, test_acc 0.5302\n",
      "epoch 66: train_loss 2.6924, train_acc 0.4862, test_loss 2.0181130929228592, test_acc 0.5283\n",
      "epoch 67: train_loss 2.5916, train_acc 0.4787, test_loss 4.159672397800076, test_acc 0.5293\n",
      "epoch 68: train_loss 2.5984, train_acc 0.4789, test_loss 3.1228659181315894, test_acc 0.5256\n",
      "epoch 69: train_loss 2.5181, train_acc 0.4863, test_loss 2.581010605724464, test_acc 0.5338\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b1(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_b1\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss 2.3955, train_acc 0.4445, test_loss 1.3501771601288148, test_acc 0.4488\n",
      "epoch 1: train_loss 2.3438, train_acc 0.4505, test_loss 1.2039489236130794, test_acc 0.4488\n",
      "epoch 2: train_loss 2.3009, train_acc 0.4451, test_loss 1.2711152300320334, test_acc 0.4534\n",
      "epoch 3: train_loss 2.3256, train_acc 0.4511, test_loss 1.4797884856761048, test_acc 0.4442\n",
      "epoch 4: train_loss 2.3433, train_acc 0.4389, test_loss 1.2405534029224892, test_acc 0.4543\n",
      "epoch 5: train_loss 2.3147, train_acc 0.4441, test_loss 1.6985297714116587, test_acc 0.4442\n",
      "epoch 6: train_loss 2.3167, train_acc 0.4464, test_loss 1.4024876534829847, test_acc 0.4479\n",
      "epoch 7: train_loss 2.2967, train_acc 0.453, test_loss 1.2248357270709775, test_acc 0.4424\n",
      "epoch 8: train_loss 2.3363, train_acc 0.4444, test_loss 1.3597585704906332, test_acc 0.4497\n",
      "epoch 9: train_loss 2.2818, train_acc 0.4383, test_loss 1.46485254380995, test_acc 0.4525\n",
      "epoch 10: train_loss 2.3191, train_acc 0.4525, test_loss 1.246889396276073, test_acc 0.447\n",
      "epoch 11: train_loss 2.3287, train_acc 0.4482, test_loss 1.2120947802960327, test_acc 0.4497\n",
      "epoch 12: train_loss 2.4192, train_acc 0.448, test_loss 1.3962551619060732, test_acc 0.4506\n",
      "epoch 13: train_loss 2.2453, train_acc 0.4451, test_loss 1.4105714679418142, test_acc 0.4516\n",
      "epoch 14: train_loss 2.4848, train_acc 0.4486, test_loss 1.4481515895296058, test_acc 0.4479\n",
      "epoch 15: train_loss 2.2632, train_acc 0.4433, test_loss 1.1995135979417038, test_acc 0.4552\n",
      "epoch 16: train_loss 2.3358, train_acc 0.4485, test_loss 1.5789128278247617, test_acc 0.4424\n",
      "epoch 17: train_loss 2.3447, train_acc 0.4515, test_loss 1.2873526203566974, test_acc 0.458\n",
      "epoch 18: train_loss 2.3385, train_acc 0.4465, test_loss 1.4151305728464283, test_acc 0.4488\n",
      "epoch 19: train_loss 2.3403, train_acc 0.4443, test_loss 1.4701899748833567, test_acc 0.4516\n",
      "epoch 20: train_loss 2.3635, train_acc 0.4415, test_loss 1.6370067765333536, test_acc 0.4406\n",
      "epoch 21: train_loss 2.2435, train_acc 0.4487, test_loss 1.3499420925947605, test_acc 0.4424\n",
      "epoch 22: train_loss 2.3678, train_acc 0.4488, test_loss 1.7693987648927316, test_acc 0.4461\n",
      "epoch 23: train_loss 2.3697, train_acc 0.4505, test_loss 1.3299977199686948, test_acc 0.4452\n",
      "epoch 24: train_loss 2.3191, train_acc 0.4475, test_loss 1.156078488125008, test_acc 0.4497\n",
      "epoch 25: train_loss 2.3495, train_acc 0.4455, test_loss 1.2973109943557266, test_acc 0.447\n",
      "epoch 26: train_loss 2.2867, train_acc 0.4513, test_loss 1.2040236396153188, test_acc 0.4479\n",
      "epoch 27: train_loss 2.3602, train_acc 0.4541, test_loss 1.4968780632210823, test_acc 0.4479\n",
      "epoch 28: train_loss 2.3174, train_acc 0.4516, test_loss 1.18876713514328, test_acc 0.4433\n",
      "epoch 29: train_loss 2.3954, train_acc 0.4491, test_loss 1.4798372929449273, test_acc 0.4479\n",
      "epoch 30: train_loss 2.3439, train_acc 0.445, test_loss 1.4065461012737406, test_acc 0.4479\n",
      "epoch 31: train_loss 2.3575, train_acc 0.4414, test_loss 1.4260490744815666, test_acc 0.4488\n",
      "epoch 32: train_loss 2.2898, train_acc 0.4488, test_loss 1.4642460555437495, test_acc 0.447\n",
      "epoch 33: train_loss 2.2862, train_acc 0.4466, test_loss 1.3342237554259013, test_acc 0.4598\n",
      "epoch 34: train_loss 2.3259, train_acc 0.4542, test_loss 1.0241765152165834, test_acc 0.4479\n",
      "epoch 35: train_loss 2.2745, train_acc 0.4452, test_loss 1.3949008572036212, test_acc 0.4543\n",
      "epoch 36: train_loss 2.3724, train_acc 0.4554, test_loss 2.0332751421213584, test_acc 0.4497\n",
      "epoch 37: train_loss 2.4363, train_acc 0.4483, test_loss 1.189852631724077, test_acc 0.447\n",
      "epoch 38: train_loss 2.3499, train_acc 0.4507, test_loss 1.2881188408984128, test_acc 0.4442\n",
      "epoch 39: train_loss 2.3211, train_acc 0.4498, test_loss 1.187063618595465, test_acc 0.4488\n",
      "epoch 40: train_loss 2.3825, train_acc 0.4481, test_loss 1.404836676565341, test_acc 0.4552\n",
      "epoch 41: train_loss 2.4347, train_acc 0.4454, test_loss 1.3743760973705452, test_acc 0.4497\n",
      "epoch 42: train_loss 2.2887, train_acc 0.4431, test_loss 1.2447829710718046, test_acc 0.4433\n",
      "epoch 43: train_loss 2.2764, train_acc 0.4486, test_loss 1.3594279324114869, test_acc 0.4552\n",
      "epoch 44: train_loss 2.3448, train_acc 0.4479, test_loss 1.4316861553209572, test_acc 0.4516\n",
      "epoch 45: train_loss 2.2736, train_acc 0.4497, test_loss 1.4147022411199985, test_acc 0.4525\n",
      "epoch 46: train_loss 2.3933, train_acc 0.439, test_loss 1.5261761317850249, test_acc 0.447\n",
      "epoch 47: train_loss 2.3599, train_acc 0.4461, test_loss 1.4048534049848316, test_acc 0.4561\n",
      "epoch 48: train_loss 2.223, train_acc 0.4478, test_loss 1.3086800836775814, test_acc 0.4516\n",
      "epoch 49: train_loss 2.3297, train_acc 0.4409, test_loss 1.31716430841024, test_acc 0.4461\n",
      "epoch 50: train_loss 2.3008, train_acc 0.4456, test_loss 1.275132462355075, test_acc 0.4461\n",
      "epoch 51: train_loss 2.398, train_acc 0.4516, test_loss 1.4153406332354224, test_acc 0.4488\n",
      "epoch 52: train_loss 2.3525, train_acc 0.4498, test_loss 1.612855973910588, test_acc 0.4497\n",
      "epoch 53: train_loss 2.3031, train_acc 0.4445, test_loss 1.870013682454334, test_acc 0.4442\n",
      "epoch 54: train_loss 2.3098, train_acc 0.448, test_loss 1.3482615036763919, test_acc 0.457\n",
      "epoch 55: train_loss 2.3592, train_acc 0.4542, test_loss 1.1747703199194817, test_acc 0.4534\n",
      "epoch 56: train_loss 2.2999, train_acc 0.455, test_loss 1.2486934453739327, test_acc 0.4452\n",
      "epoch 57: train_loss 2.3635, train_acc 0.444, test_loss 1.3565563665229616, test_acc 0.4488\n",
      "epoch 58: train_loss 2.3184, train_acc 0.4452, test_loss 1.8632165584747273, test_acc 0.4534\n",
      "epoch 59: train_loss 2.3166, train_acc 0.4491, test_loss 1.158266197174951, test_acc 0.4497\n",
      "epoch 60: train_loss 2.3353, train_acc 0.4407, test_loss 1.4190461116909328, test_acc 0.4488\n",
      "epoch 61: train_loss 2.439, train_acc 0.4522, test_loss 1.330611865579319, test_acc 0.4497\n",
      "epoch 62: train_loss 2.3955, train_acc 0.4464, test_loss 1.4803574064531972, test_acc 0.4525\n",
      "epoch 63: train_loss 2.2767, train_acc 0.4507, test_loss 1.258361277240286, test_acc 0.4488\n",
      "epoch 64: train_loss 2.3599, train_acc 0.4508, test_loss 1.2172063611979023, test_acc 0.4442\n",
      "epoch 65: train_loss 2.3521, train_acc 0.4442, test_loss 1.2282759484033043, test_acc 0.4497\n",
      "epoch 66: train_loss 2.3614, train_acc 0.4538, test_loss 1.3742517877976246, test_acc 0.447\n",
      "epoch 67: train_loss 2.2891, train_acc 0.4402, test_loss 1.3803420127854704, test_acc 0.447\n",
      "epoch 68: train_loss 2.3136, train_acc 0.45, test_loss 1.3479833768534268, test_acc 0.4461\n",
      "epoch 69: train_loss 2.3967, train_acc 0.4393, test_loss 1.325341660645152, test_acc 0.4424\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b2(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_b2\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss 3.6635, train_acc 0.4995, test_loss 2.9989221259488485, test_acc 0.5174\n",
      "epoch 1: train_loss 3.7573, train_acc 0.5006, test_loss 3.803492504565328, test_acc 0.5146\n",
      "epoch 2: train_loss 3.899, train_acc 0.4955, test_loss 2.5495735003699767, test_acc 0.5311\n",
      "epoch 3: train_loss 3.7823, train_acc 0.4976, test_loss 2.6692805422071566, test_acc 0.5256\n",
      "epoch 4: train_loss 3.798, train_acc 0.501, test_loss 2.501239156483296, test_acc 0.5183\n",
      "epoch 5: train_loss 3.9068, train_acc 0.4974, test_loss 2.651037236018416, test_acc 0.5229\n",
      "epoch 6: train_loss 3.7092, train_acc 0.5041, test_loss 2.6691781942761574, test_acc 0.5311\n",
      "epoch 7: train_loss 3.649, train_acc 0.5097, test_loss 2.539135395935728, test_acc 0.5201\n",
      "epoch 8: train_loss 3.8652, train_acc 0.4986, test_loss 3.1363655784230344, test_acc 0.5165\n",
      "epoch 9: train_loss 3.8377, train_acc 0.499, test_loss 2.200179038906446, test_acc 0.5027\n",
      "epoch 10: train_loss 3.8121, train_acc 0.4958, test_loss 1.989823589813121, test_acc 0.5311\n",
      "epoch 11: train_loss 3.8238, train_acc 0.501, test_loss 3.020609248926696, test_acc 0.5155\n",
      "epoch 12: train_loss 3.8001, train_acc 0.5022, test_loss 2.4399506128248394, test_acc 0.5101\n",
      "epoch 13: train_loss 3.8192, train_acc 0.4976, test_loss 2.684708109939338, test_acc 0.5274\n",
      "epoch 14: train_loss 3.7964, train_acc 0.5012, test_loss 4.992291694694289, test_acc 0.5018\n",
      "epoch 15: train_loss 3.7523, train_acc 0.506, test_loss 4.0162775665794035, test_acc 0.5183\n",
      "epoch 16: train_loss 3.8567, train_acc 0.5008, test_loss 2.726518534873042, test_acc 0.5165\n",
      "epoch 17: train_loss 3.9704, train_acc 0.4979, test_loss 4.724980218536893, test_acc 0.5165\n",
      "epoch 18: train_loss 3.7737, train_acc 0.4985, test_loss 2.966429806496587, test_acc 0.5128\n",
      "epoch 19: train_loss 3.6884, train_acc 0.4935, test_loss 3.3740949009628576, test_acc 0.5174\n",
      "epoch 20: train_loss 3.8124, train_acc 0.5018, test_loss 2.6357120530478917, test_acc 0.5165\n",
      "epoch 21: train_loss 3.698, train_acc 0.499, test_loss 2.893026028298373, test_acc 0.5283\n",
      "epoch 22: train_loss 3.8019, train_acc 0.5005, test_loss 3.0543947487906085, test_acc 0.5128\n",
      "epoch 23: train_loss 3.7935, train_acc 0.5006, test_loss 2.9199875122450387, test_acc 0.5201\n",
      "epoch 24: train_loss 3.8641, train_acc 0.4975, test_loss 3.1900406947301554, test_acc 0.5274\n",
      "epoch 25: train_loss 3.8606, train_acc 0.4953, test_loss 2.1324417523535777, test_acc 0.5219\n",
      "epoch 26: train_loss 3.7328, train_acc 0.5015, test_loss 3.825774062486192, test_acc 0.521\n",
      "epoch 27: train_loss 3.9411, train_acc 0.4932, test_loss 2.827462665341672, test_acc 0.521\n",
      "epoch 28: train_loss 3.8045, train_acc 0.505, test_loss 2.7417879976345807, test_acc 0.5183\n",
      "epoch 29: train_loss 3.9155, train_acc 0.4992, test_loss 3.9488818702139845, test_acc 0.5219\n",
      "epoch 30: train_loss 3.7784, train_acc 0.5028, test_loss 2.7721966648886367, test_acc 0.521\n",
      "epoch 31: train_loss 3.8471, train_acc 0.5019, test_loss 4.130345793703139, test_acc 0.5183\n",
      "epoch 32: train_loss 3.9019, train_acc 0.4956, test_loss 2.932300734999411, test_acc 0.5265\n",
      "epoch 33: train_loss 3.7692, train_acc 0.4949, test_loss 2.813710003382981, test_acc 0.5229\n",
      "epoch 34: train_loss 3.9048, train_acc 0.497, test_loss 3.795957678632719, test_acc 0.5274\n",
      "epoch 35: train_loss 3.8, train_acc 0.5013, test_loss 2.0254102563945207, test_acc 0.5183\n",
      "epoch 36: train_loss 4.0488, train_acc 0.499, test_loss 3.6618275398310187, test_acc 0.5091\n",
      "epoch 37: train_loss 3.7324, train_acc 0.5012, test_loss 3.223433520828784, test_acc 0.5265\n",
      "epoch 38: train_loss 3.8047, train_acc 0.5006, test_loss 4.434666097708987, test_acc 0.5183\n",
      "epoch 39: train_loss 3.8556, train_acc 0.4976, test_loss 2.5166228063799565, test_acc 0.5283\n",
      "epoch 40: train_loss 3.8136, train_acc 0.4992, test_loss 2.7195529190234335, test_acc 0.5247\n",
      "epoch 41: train_loss 3.8527, train_acc 0.4954, test_loss 2.631761879328182, test_acc 0.5219\n",
      "epoch 42: train_loss 3.8206, train_acc 0.4927, test_loss 2.6274558024606933, test_acc 0.5229\n",
      "epoch 43: train_loss 3.8538, train_acc 0.4941, test_loss 3.827687169341762, test_acc 0.5183\n",
      "epoch 44: train_loss 3.9327, train_acc 0.4933, test_loss 2.3537869799943465, test_acc 0.5192\n",
      "epoch 45: train_loss 3.7539, train_acc 0.4952, test_loss 3.9464589924001605, test_acc 0.5146\n",
      "epoch 46: train_loss 3.7796, train_acc 0.4968, test_loss 4.328534749351864, test_acc 0.5119\n",
      "epoch 47: train_loss 4.0217, train_acc 0.4986, test_loss 4.205764976236458, test_acc 0.521\n",
      "epoch 48: train_loss 3.8134, train_acc 0.5034, test_loss 2.1832998270471964, test_acc 0.5229\n",
      "epoch 49: train_loss 3.7904, train_acc 0.5026, test_loss 2.478927134159932, test_acc 0.5174\n",
      "epoch 50: train_loss 3.9528, train_acc 0.5015, test_loss 2.517892542661217, test_acc 0.5229\n",
      "epoch 51: train_loss 3.8093, train_acc 0.4924, test_loss 3.9202856191551447, test_acc 0.5119\n",
      "epoch 52: train_loss 3.7632, train_acc 0.4967, test_loss 3.2808204814110637, test_acc 0.5219\n",
      "epoch 53: train_loss 3.8877, train_acc 0.4979, test_loss 2.8072279558757107, test_acc 0.5229\n",
      "epoch 54: train_loss 3.811, train_acc 0.5021, test_loss 3.8357860401300017, test_acc 0.5128\n",
      "epoch 55: train_loss 3.8185, train_acc 0.4999, test_loss 2.5123446549968267, test_acc 0.5091\n",
      "epoch 56: train_loss 3.8893, train_acc 0.4955, test_loss 1.7202505025828778, test_acc 0.5274\n",
      "epoch 57: train_loss 3.7934, train_acc 0.5046, test_loss 3.3164299225240566, test_acc 0.521\n",
      "epoch 58: train_loss 3.7453, train_acc 0.4986, test_loss 2.071489467045507, test_acc 0.511\n",
      "epoch 59: train_loss 3.8382, train_acc 0.4945, test_loss 3.3623610758912195, test_acc 0.5293\n",
      "epoch 60: train_loss 3.7786, train_acc 0.5027, test_loss 2.8718419296214086, test_acc 0.5283\n",
      "epoch 61: train_loss 3.9235, train_acc 0.4921, test_loss 5.296535241102606, test_acc 0.5174\n",
      "epoch 62: train_loss 3.6906, train_acc 0.505, test_loss 3.0469094665220493, test_acc 0.5238\n",
      "epoch 63: train_loss 3.6333, train_acc 0.5001, test_loss 3.7206309102135124, test_acc 0.5091\n",
      "epoch 64: train_loss 3.9156, train_acc 0.497, test_loss 3.1737019311793326, test_acc 0.5119\n",
      "epoch 65: train_loss 3.8044, train_acc 0.513, test_loss 3.997392160909921, test_acc 0.5274\n",
      "epoch 66: train_loss 3.8759, train_acc 0.4932, test_loss 3.0202803062564496, test_acc 0.521\n",
      "epoch 67: train_loss 3.8395, train_acc 0.4981, test_loss 2.278536163910651, test_acc 0.5256\n",
      "epoch 68: train_loss 3.7801, train_acc 0.5003, test_loss 4.422169061421912, test_acc 0.5055\n",
      "epoch 69: train_loss 3.758, train_acc 0.4926, test_loss 3.1035070768004145, test_acc 0.5256\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b3(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_b3\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss 2.1891, train_acc 0.5143, test_loss 2.9527932673529254, test_acc 0.4717\n",
      "epoch 1: train_loss 2.1638, train_acc 0.5105, test_loss 2.9602517661054564, test_acc 0.4771\n",
      "epoch 2: train_loss 2.2029, train_acc 0.5091, test_loss 4.062865914112907, test_acc 0.4698\n",
      "epoch 3: train_loss 2.2607, train_acc 0.507, test_loss 2.9801703365672876, test_acc 0.457\n",
      "epoch 4: train_loss 2.3721, train_acc 0.4998, test_loss 4.0095533298182096, test_acc 0.468\n",
      "epoch 5: train_loss 2.2555, train_acc 0.51, test_loss 2.656771469813596, test_acc 0.468\n",
      "epoch 6: train_loss 2.3189, train_acc 0.5118, test_loss 4.672930087969116, test_acc 0.4717\n",
      "epoch 7: train_loss 2.3025, train_acc 0.5009, test_loss 4.0043778398791, test_acc 0.4561\n",
      "epoch 8: train_loss 2.2065, train_acc 0.5095, test_loss 3.2471170891791417, test_acc 0.4698\n",
      "epoch 9: train_loss 2.2769, train_acc 0.5069, test_loss 2.461978888816764, test_acc 0.4625\n",
      "epoch 10: train_loss 2.4345, train_acc 0.51, test_loss 2.8946651595166224, test_acc 0.4589\n",
      "epoch 11: train_loss 2.2325, train_acc 0.5079, test_loss 3.8449482197517453, test_acc 0.4744\n",
      "epoch 12: train_loss 2.2972, train_acc 0.5071, test_loss 2.1609420645607456, test_acc 0.468\n",
      "epoch 13: train_loss 2.3206, train_acc 0.5115, test_loss 3.6638767976429607, test_acc 0.4781\n",
      "epoch 14: train_loss 2.2223, train_acc 0.5053, test_loss 3.543165554621102, test_acc 0.4653\n",
      "epoch 15: train_loss 2.282, train_acc 0.5082, test_loss 3.7755485762189904, test_acc 0.4698\n",
      "epoch 16: train_loss 2.2777, train_acc 0.5119, test_loss 4.482922842559256, test_acc 0.4461\n",
      "epoch 17: train_loss 2.29, train_acc 0.5025, test_loss 6.312982784328774, test_acc 0.458\n",
      "epoch 18: train_loss 2.2506, train_acc 0.5112, test_loss 3.811710151283571, test_acc 0.4653\n",
      "epoch 19: train_loss 2.3173, train_acc 0.5057, test_loss 3.0958903971276293, test_acc 0.4744\n",
      "epoch 20: train_loss 2.2016, train_acc 0.5055, test_loss 4.252055972501282, test_acc 0.4707\n",
      "epoch 21: train_loss 2.3427, train_acc 0.5132, test_loss 3.9321666325032165, test_acc 0.4726\n",
      "epoch 22: train_loss 2.2443, train_acc 0.5072, test_loss 4.505890153661724, test_acc 0.4762\n",
      "epoch 23: train_loss 2.2067, train_acc 0.507, test_loss 2.9984146966794727, test_acc 0.4625\n",
      "epoch 24: train_loss 2.2258, train_acc 0.516, test_loss 3.8283284237877324, test_acc 0.4762\n",
      "epoch 25: train_loss 2.2515, train_acc 0.5058, test_loss 2.6468359638393686, test_acc 0.4771\n",
      "epoch 26: train_loss 2.3458, train_acc 0.4955, test_loss 2.5617320391552103, test_acc 0.4662\n",
      "epoch 27: train_loss 2.3496, train_acc 0.5123, test_loss 3.5853010958683775, test_acc 0.4735\n",
      "epoch 28: train_loss 2.2927, train_acc 0.5062, test_loss 3.2364058492388543, test_acc 0.4534\n",
      "epoch 29: train_loss 2.2001, train_acc 0.5169, test_loss 3.347603306909802, test_acc 0.458\n",
      "epoch 30: train_loss 2.32, train_acc 0.4994, test_loss 4.010942846155253, test_acc 0.4717\n",
      "epoch 31: train_loss 2.2413, train_acc 0.5153, test_loss 3.6472793427420274, test_acc 0.4707\n",
      "epoch 32: train_loss 2.1907, train_acc 0.5038, test_loss 3.469633601265372, test_acc 0.4689\n",
      "epoch 33: train_loss 2.1661, train_acc 0.5067, test_loss 2.4780205939326034, test_acc 0.4625\n",
      "epoch 34: train_loss 2.3761, train_acc 0.495, test_loss 2.9720868568533736, test_acc 0.4662\n",
      "epoch 35: train_loss 2.2014, train_acc 0.5104, test_loss 4.017768195385907, test_acc 0.4689\n",
      "epoch 36: train_loss 2.3012, train_acc 0.51, test_loss 2.6319433054060997, test_acc 0.468\n",
      "epoch 37: train_loss 2.2502, train_acc 0.5046, test_loss 1.7307319205247507, test_acc 0.4598\n",
      "epoch 38: train_loss 2.4118, train_acc 0.5015, test_loss 2.6203195166108375, test_acc 0.4717\n",
      "epoch 39: train_loss 2.2342, train_acc 0.5007, test_loss 4.289204847442167, test_acc 0.4762\n",
      "epoch 40: train_loss 2.308, train_acc 0.5126, test_loss 2.5874662610686894, test_acc 0.4598\n",
      "epoch 41: train_loss 2.291, train_acc 0.5053, test_loss 2.7552942195583743, test_acc 0.4698\n",
      "epoch 42: train_loss 2.3365, train_acc 0.5062, test_loss 3.2118662262311584, test_acc 0.4707\n",
      "epoch 43: train_loss 2.305, train_acc 0.5148, test_loss 2.327109483085995, test_acc 0.4671\n",
      "epoch 44: train_loss 2.2139, train_acc 0.4983, test_loss 4.40926250265111, test_acc 0.4808\n",
      "epoch 45: train_loss 2.2134, train_acc 0.5122, test_loss 2.1371113607281957, test_acc 0.4781\n",
      "epoch 46: train_loss 2.2802, train_acc 0.5125, test_loss 4.371969082237816, test_acc 0.4707\n",
      "epoch 47: train_loss 2.3684, train_acc 0.5033, test_loss 3.251397560021995, test_acc 0.4753\n",
      "epoch 48: train_loss 2.3049, train_acc 0.5098, test_loss 3.130513225220675, test_acc 0.4543\n",
      "epoch 49: train_loss 2.2827, train_acc 0.5087, test_loss 2.2172491456734416, test_acc 0.4625\n",
      "epoch 50: train_loss 2.2474, train_acc 0.513, test_loss 3.5963417176136807, test_acc 0.4717\n",
      "epoch 51: train_loss 2.2743, train_acc 0.5043, test_loss 3.468928244475691, test_acc 0.4726\n",
      "epoch 52: train_loss 2.2448, train_acc 0.5065, test_loss 2.7082979936268474, test_acc 0.4689\n",
      "epoch 53: train_loss 2.3421, train_acc 0.5066, test_loss 3.989033558033066, test_acc 0.468\n",
      "epoch 54: train_loss 2.2635, train_acc 0.5067, test_loss 3.418595666859224, test_acc 0.4671\n",
      "epoch 55: train_loss 2.262, train_acc 0.5128, test_loss 1.9848983019753828, test_acc 0.4634\n",
      "epoch 56: train_loss 2.2833, train_acc 0.5045, test_loss 3.283041116252024, test_acc 0.468\n",
      "epoch 57: train_loss 2.3854, train_acc 0.5081, test_loss 3.0398044834625133, test_acc 0.4644\n",
      "epoch 58: train_loss 2.2847, train_acc 0.5015, test_loss 3.4282702434215513, test_acc 0.4616\n",
      "epoch 59: train_loss 2.2942, train_acc 0.5143, test_loss 3.769902137232437, test_acc 0.4625\n",
      "epoch 60: train_loss 2.1056, train_acc 0.5177, test_loss 2.4022484488199574, test_acc 0.479\n",
      "epoch 61: train_loss 2.2775, train_acc 0.5037, test_loss 1.9923523916186971, test_acc 0.4634\n",
      "epoch 62: train_loss 2.2333, train_acc 0.51, test_loss 3.204559235511794, test_acc 0.4717\n",
      "epoch 63: train_loss 2.3487, train_acc 0.5049, test_loss 3.5920440174325945, test_acc 0.4698\n",
      "epoch 64: train_loss 2.2614, train_acc 0.5092, test_loss 3.9674738229301774, test_acc 0.4726\n",
      "epoch 65: train_loss 2.2629, train_acc 0.5104, test_loss 2.589455057105809, test_acc 0.4598\n",
      "epoch 66: train_loss 2.3291, train_acc 0.51, test_loss 4.033087288385335, test_acc 0.4717\n",
      "epoch 67: train_loss 2.323, train_acc 0.5071, test_loss 4.080683699037737, test_acc 0.4726\n",
      "epoch 68: train_loss 2.4241, train_acc 0.4972, test_loss 2.265168682094902, test_acc 0.457\n",
      "epoch 69: train_loss 2.383, train_acc 0.5101, test_loss 6.591518067409178, test_acc 0.4717\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b4(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_b4\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\makeup-removal\\src\\train\\Classifcation\\Classification.ipynb Cell 24\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m highest_test_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m# Train phase\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_model(model, loss_function, optimizer, train_loader, writer, i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# Test phase\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m eval_model(model, loss_function, test_loader, writer, i)\n",
      "\u001b[1;32me:\\makeup-removal\\src\\train\\Classifcation\\Classification.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Calculate gradient from loss\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Update weight\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/makeup-removal/src/train/Classifcation/Classification.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\python_pytorch\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\python_pytorch\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_v2_s(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_v2_s\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_v2_m(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_v2_m\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_v2_l(num_classes=2)\n",
    "model = model.to(device)\n",
    "model_name = \"efficientnet_v2_l\"\n",
    "list_root_dir = []\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"gan_makeup_data_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"mtdataset_96\"))\n",
    "list_root_dir.append(os.path.join(os.path.dirname(\n",
    "    os.getcwd()), \"dataset\", \"data_anh_Vinh\"))\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop([96, 96]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([96, 96]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "epoch = 70\n",
    "\n",
    "# Perform train-test split\n",
    "train_dataset = ImageDataset(list_root_dir, train_transform)\n",
    "test_dataset = ImageDataset(list_root_dir, test_transform)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, train_size=0.9)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Keep track best result\n",
    "lowest_train_loss = math.inf\n",
    "highest_train_acc = 0\n",
    "lowest_test_loss = math.inf\n",
    "highest_test_acc = 0\n",
    "for i in range(epoch):\n",
    "    # Train phase\n",
    "    train_loss, train_acc = train_model(model, loss_function, optimizer, train_loader, writer, i)\n",
    "    \n",
    "    # Test phase\n",
    "    test_loss, test_acc = eval_model(model, loss_function, test_loader, writer, i)\n",
    "    \n",
    "    # Command line log\n",
    "    print(f'''epoch {i}: train_loss {round(train_loss,4)}, train_acc {round(train_acc,4)}, test_loss {test_loss}, test_acc {round(test_acc,4)}''')\n",
    "\n",
    "    # Save the best model\n",
    "    if train_loss <= lowest_train_loss and train_acc >= highest_train_acc and test_loss <= lowest_test_loss and test_acc >= highest_test_acc:\n",
    "        lowest_train_loss = train_loss\n",
    "        highest_train_acc = train_acc\n",
    "        lowest_test_loss = test_loss\n",
    "        highest_test_acc = test_acc\n",
    "        saved_folder = os.path.join(os.getcwd(),f\"{model_name}\")\n",
    "        if not os.path.exists(saved_folder):\n",
    "            os.makedirs(saved_folder)\n",
    "        saved_path = os.path.join(saved_folder, f\"{i}.pth\")\n",
    "        torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
